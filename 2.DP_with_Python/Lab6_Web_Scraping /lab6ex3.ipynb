{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Task: Collect Data from Multiple Websites\n",
    "\n",
    "**Goal:**\n",
    "Make requests to **at least 3 websites** to obtain the desired information (your choice), for example:\n",
    "\n",
    "- Weather data\n",
    "- Exchange rates\n",
    "- Product prices\n",
    "- Hotel or restaurant ratings\n",
    "\n",
    "**Output:**\n",
    "You should produce **3 CSV files** containing similar data. Examples:\n",
    "\n",
    "- Weather data for October from 3 different weather forecast sites.\n",
    "- Exchange rates for one month from 3 different banks.\n",
    "- Ratings for a list of hotels from 3 different websites.\n",
    "\n",
    "**Note:**\n",
    "Make sure the websites **allow web scraping** before accessing their data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meteo_newyork.csv salvat! → 9 linii\n",
      "meteo_losangeles.csv salvat! → 9 linii\n",
      "meteo_chicago.csv salvat! → 9 linii\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "def scrape_weather(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    days = [d.get_text(strip=True) for d in soup.select(\".tombstone-container .period-name\")]\n",
    "    temps = [t.get_text(strip=True) for t in soup.select(\".tombstone-container .temp\")]\n",
    "\n",
    "    n = min(len(days), len(temps))\n",
    "    return pd.DataFrame({\"Day\": days[:n], \"Temperature\": temps[:n]})\n",
    "\n",
    "\n",
    "# 1️ New York\n",
    "url_ny = \"https://forecast.weather.gov/MapClick.php?lat=40.71&lon=-74.01\"\n",
    "data_ny = scrape_weather(url_ny)\n",
    "data_ny.to_csv(\"meteo_newyork.csv\", index=False)\n",
    "print(\"meteo_newyork.csv salvat! →\", len(data_ny), \"linii\")\n",
    "\n",
    "\n",
    "# 2️ Los Angeles\n",
    "url_la = \"https://forecast.weather.gov/MapClick.php?lat=34.05&lon=-118.25\"\n",
    "data_la = scrape_weather(url_la)\n",
    "data_la.to_csv(\"meteo_losangeles.csv\", index=False)\n",
    "print(\"meteo_losangeles.csv salvat! →\", len(data_la), \"linii\")\n",
    "\n",
    "\n",
    "#  Chicago\n",
    "url_chi = \"https://forecast.weather.gov/MapClick.php?lat=41.88&lon=-87.63\"\n",
    "data_chi = scrape_weather(url_chi)\n",
    "data_chi.to_csv(\"meteo_chicago.csv\", index=False)\n",
    "print(\"meteo_chicago.csv salvat! →\", len(data_chi), \"linii\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site 1 CSV saved: 30 books\n",
      "Site 2 CSV saved: 100 quotes\n",
      "Site 3 CSV saved: 14 books\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "# Books to Scrape - Top 30 books \n",
    "base_url_books = 'http://books.toscrape.com/catalogue/page-{}.html'\n",
    "all_books = []\n",
    "\n",
    "for i in range(1, 51): \n",
    "    url = base_url_books.format(i)\n",
    "    response = requests.get(url, headers=headers) \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    books = soup.select('.product_pod')\n",
    "    for book in books:\n",
    "        title = book.select('h3 a')[0]['title']\n",
    "        price = book.select('p.price_color')[0].text\n",
    "        all_books.append([title, price])\n",
    "\n",
    "    if len(all_books) >= 30:  \n",
    "        break\n",
    "\n",
    "df_top30 = pd.DataFrame(all_books[:30], columns=['Title', 'Price'])\n",
    "df_top30.to_csv('top30_books.csv', index=False)\n",
    "print(\"Site 1 CSV saved:\", len(df_top30), \"books\")\n",
    "\n",
    "# Quotes to Scrape - all the quotes\n",
    "base_url_quotes = 'http://quotes.toscrape.com/page/{}/'\n",
    "all_quotes = []\n",
    "\n",
    "for i in range(1, 11):  \n",
    "    url = base_url_quotes.format(i)\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    quotes = soup.find_all('div', class_='quote')\n",
    "    for quote in quotes:\n",
    "        text = quote.find('span', class_='text').text\n",
    "        author = quote.find('small', class_='author').text\n",
    "        all_quotes.append([text, author])\n",
    "\n",
    "df_quotes = pd.DataFrame(all_quotes, columns=['Quote', 'Author'])\n",
    "df_quotes.to_csv('quotes_all.csv', index=False)\n",
    "print(\"Site 2 CSV saved:\", len(df_quotes), \"quotes\")\n",
    "\n",
    "# Books to Scrape - 'Science' category\n",
    "url_science = \"http://books.toscrape.com/catalogue/category/books/science_22/index.html\"\n",
    "response_science = requests.get(url_science, headers=headers)\n",
    "soup_science = BeautifulSoup(response_science.text, 'html.parser')\n",
    "\n",
    "science_books = []\n",
    "books_science = soup_science.select('.product_pod')\n",
    "for book in books_science:\n",
    "    title = book.select('h3 a')[0]['title']\n",
    "    price = book.select('p.price_color')[0].text\n",
    "    science_books.append([title, price])\n",
    "\n",
    "df_science = pd.DataFrame(science_books, columns=['Title', 'Price'])\n",
    "df_science.to_csv('science_books.csv', index=False)\n",
    "print(\"Site 3 CSV saved:\", len(df_science), \"books\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
